config:
  attenuator:
    # Each attenuator is named.
    #
    # Individual things (global, service, backend, gateway) refer to
    # them by name.
    "google":
      # Google allow us to do 1 per second max
      hertz: 1.0
      # TODO(john): 429 handling
    "bing":
      # Bing allow us to do 1 every 2 seconds max
      hertz: 0.5
      # TODO(john): 429 handling
    # Maximum number of inflight requests.
    #
    # TODO(john): allow this to be over-ridden on a service-by-service
    # (and backend-by-backend) basis
    max_inflight: 100
  broker:
    listen: 0.0.0.0:8888
    upstream:
      # alex1m service
      # This is a contrived service broker which simply spreads requests
      # across the top 10 sites from the Alexa Top Million list
      #
      # This is mainly to give us nice eye-candy in grafana and verify
      # that all of the metrics are doing what we expect them to do
      "alexa1m":
        # TODO(john): hook up the TRIBE billing engine
        cost:
          alexa1m: 1
        backends:
          amazon.com:
            impl: proxy
            url: https://amazon.com
            # 'weight' is used to calculate a CDF so we spread load in
            # a weighted manner
            #
            # See: service_map.go
            weight: 1
            # 'cost' is a placeholder, and a TODO(john) when hooked up to TRIBE.
            # For now, it's 'how many cents did we charge you for this'
            cost:
          baidu.com:
            impl: proxy
            url: https://baidu.com
            weight: 8
            cost:
          bilibili.com:
            impl: proxy
            url: https://bilibili.com
            weight: 7
            cost:
          facebook.com:
            impl: proxy
            url: https://facebook.com
            weight: 6
            cost:
          google.com:
            impl: proxy
            url: https://google.com
            weight: 10
            cost:
          qq.com:
            impl: proxy
            url: https://qq.com
            weight: 5
            cost:
          twitter.com:
            impl: proxy
            url: https://twitter.com
            weight: 4
            cost:
          wikipedia.org:
            impl: proxy
            url: https://wikipedia.com
            weight: 2
            cost:
          youtube.com:
            impl: proxy
            url: https://youtube.com
            weight: 9
            cost:
          zhihu.com:
            impl: proxy
            url: https://zhihu.com
            weight: 3
            cost:
        rule: weighted
      # Name of this service.
      # We use this to map /api/v1/broker/{SERVICE} to the service map
      "search":
        # The cost of this service, as per TRIBE
        cost:
          search: 1
        # /api/v1/broker/search will randomly choose between bing and google
        # backends
        bing:
          impl: proxy
          # The URL to forward-proxy the request to
          url: https://www.bing.com
          # Any URL (or POST) params that we want to map
          params:
            # Keep the 'q=' parameter exactly as it is, i.e.
            # we don't need to rename it or map it in any way
            q: q
          # Any headers we want to send to the upstream
          headers:
            X-Alizee: wiggle
          record:
            # directory where to store requests and responses.
            # A blank value means we are not recording this thing - so
            # you could (if you wanted) only record requests or only
            # record responses.
            requests: search
            responses: search
          circuitbreaker:
            max_concurrent: 2
            max_hertz: 2
            retries: 3
            timeout_millis: 10000
        google:
          impl: proxy
          url: https://www.google.com
          params:
            # Keep the 'q=' parameter exactly as it is, i.e.
            # we don't need to rename it or map it in any way
            q: q
          circuitbreaker:
            max_concurrent: 2
            max_hertz: 2
            retries: 3
            timeout_millis: 10000
        rule: random
      "storage":
        backends:
          # TODO(john): be able to integrate with lots of storage providers
          drive:
            # Google drive
            impl: internal
          onedrive:
            # MS Onedrive
            impl: internal
          s3:
            # Amazon S3
            impl: internal
        # a 'direct' rule means that the backend must be specified
        # (akthough quite why I would ever need such a thing is lost on me)
        rule: direct
  gateway:
    # The gateway is just an ordinary forward proxy:
    #
    # http://.../api/v1/gateway/https://foo.com?param1=value
    #
    # will just be proxied to https://foo.com?param1=value
    listen: 0.0.0.0:8888
    record:
      # directory where to store requests and responses.
      # A blank value means we are not recording this thing - so
      # you could (if you wanted) only record requests or only
      # record responses.
      requests: saved-requests-and-responses
      responses: saved-requests-and-responses
  proxy:
    enable: true
    listen: 0.0.0.0:8080
  redis:
    host: localhost:6379
    pool_size: 10
    # idle timeout in millis
    timeout: 5000
  # Server pathology
  pathologies:
    # A named pathology profile.
    #
    # This allows us to easily create pathologies which have specific
    # behaviour and then just refer to them by name in a particular
    # server config.
    #
    # e.g.
    #
    # server:
    #   host: *.foo.com
    #   pathology: random_404
    #
    # This ability will become even more imortant / useful as we
    # extend the config API to allow backend servers to be created
    # and configured programatically
    simple:
      # The http code pathology 
      httpcode:
        # Weight of this pathology in the profile
        weight: 90
        # How long requests are to take (in seconds)
        #
        # Currently supported:
        #
        #   normal(mean, stddev)
        #   poisson(mean)
        #
        # normal(1.0, 0.2) returns values between ~0.2 < value < ~1.6
        # in a normal distribution and the request will sleep for that
        # amount of time
        duration: normal(1.0, 0.2)
        # The HTTP codes to return, and the weight for each return code.
        # The weights do not need to add up to 100, I just made them add
        # up to 100 here so its easy to grok the % of time that code is returned
        responses:
          200:
            weight: 80
            headers:
              # any headers that we want the handler to return when this code
              # is selected according to the cdf
              Content-type: [
                application/json
              ]
            # any response body we want the handler to return when this code
            # is selected according to the cdf
            body: '{"success": true, "pathology": "simple", "handler": "httpcode"}'
          401:
            # a 401 does not have any delay to it - it returns immediately
            duration: 0s
            weight: 5
          404:
            # a 404 does not have any delay to it - it returns immediately
            duration: 0s
            weight: 1
          429:
            # a 429 does not have any delay to it - it returns immediately
            duration: 0s
            weight: 5
            # The headers to return when we encounter this code
            headers:
              X-Backoff-Millis: [
                60000
              ]
              X-Retry-After: [
                now() + 60s
              ]
          500:
            # We can override the duration for specific responses, e.g.
            # if we want them to take longer or shorter
            #
            # In this case, a 500 response takes longer (to simulate the
            # fact that the server tried to do some things at the backend
            # and things went wrong)
            duration: normal(2.0, 0.2)
            weight: 9
      # For the timeout pathology, the number of milliseconds to sleep for
      # when handling a request
      timeout:
        # Weight of this pathology in the profile
        weight: 10
        # normal(1.0, 0.2) returns values between ~0.2 < value < ~1.6
        # in a normal distribution and the request will sleep for that
        # amount of time
        duration: normal(1.0, 0.2)
        responses:
          200:
            headers:
              # any headers that we want the handler to return when this code
              # is selected according to the cdf
              Content-type: [
                application/json
              ]
            # any response body we want the handler to return when this code
            # is selected according to the cdf
            body: '{"success": true, "pathology": "simple", "handler": "timeout"}'
    # The 'good_boy' profile always returns HTTP 200 with no delay
    good_boy:
      httpcode:
        responses:
          200:
            headers:
              Content-type: [
                application/json
              ]
            body: '{"success": true, "pathology": "good_boy"}'
  # Here we define our servers.
  #
  # They are mapped to particular hostnames (from the Host: header)
  # and the pathology profile can be selected
  #
  # TODO(john): TLS / SNI
  server:
    enable: true
    name: default
    listen: 0.0.0.0:8888
    hosts:
      # If there is no Host: match, this is the default
      default:
        pathology: simple
      goodboy.com:
        pathology: good_boy


